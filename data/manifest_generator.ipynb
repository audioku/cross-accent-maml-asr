{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "from unidecode import unidecode\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './CommonVoice2_dataset/validated.tsv'\n",
    "clips_path = './data/CommonVoice2_dataset/clips'\n",
    "manifest_path = './manifests'\n",
    "labels_path = './labels'\n",
    "invalid_clips = [\n",
    "    'common_voice_en_18406522.mp3',\n",
    "    'common_voice_en_18406523.mp3',\n",
    "    'common_voice_en_18406525.mp3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(644119, 8)\n",
      "(298721, 8)\n",
      "(298718, 8)\n",
      "(288560, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data table\n",
    "df = pd.read_table(file_path)\n",
    "print(df.shape)\n",
    "\n",
    "# Filter NA\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "# Filter out invalid clips\n",
    "df = df[~df['path'].isin(invalid_clips)]\n",
    "print(df.shape)\n",
    "\n",
    "# Filter unneccesary accent\n",
    "df = df[df['accent'] != 'other']\n",
    "print(df.shape)\n",
    "\n",
    "# Add prefix path to clips path\n",
    "df['path'] = df['path'].apply(lambda path: '{}/{}'.format(clips_path, path))\n",
    "\n",
    "# Clean up sentence text\n",
    "df['sentence'] = df['sentence'].apply(lambda sentence: unidecode(sentence.lower()))\n",
    "\n",
    "# Save manifest per accent\n",
    "for accent in df['accent'].unique():\n",
    "    df.loc[df['accent'] == accent,['path','sentence']].to_csv('{}/cv_20190612_{}.csv'.format(manifest_path, accent), index=False, header=False)\n",
    "    \n",
    "# Prepare label list\n",
    "char_list = set()\n",
    "for sentence in df.sentence:\n",
    "    for char in unidecode(sentence.lower()):\n",
    "        char_list.add(char)\n",
    "char_list = list(char_list)\n",
    "char_list.remove('_')\n",
    "char_list.insert(0, '_')\n",
    "\n",
    "char_dict = {idx: char for idx,char in enumerate(char_list)}\n",
    "\n",
    "# Save label list\n",
    "with open('{}/cv_labels.json'.format(labels_path), 'w') as f:\n",
    "    json.dump(char_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "for accent in df['accent'].unique():\n",
    "    acc_char_list = set()\n",
    "    for sentence in df.loc[df['accent'] == accent,'sentence']:\n",
    "        for char in sentence.lower():\n",
    "            acc_char_list.add(char)\n",
    "    print(acc_char_list - set(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (env_py3.7)",
   "language": "python",
   "name": "env_py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
